# C++ Boost RAG System

A comprehensive Retrieval-Augmented Generation (RAG) system designed specifically for C++ Boost library documentation and mailing list archives. This system provides intelligent question-answering capabilities by combining advanced document processing, semantic search, and large language models.

## ğŸš€ Features

### Core Capabilities
- **Multi-format Document Processing**: Handles HTML, JSON, text, and email archives
- **Semantic Chunking**: Intelligent document segmentation preserving context
- **Hybrid Retrieval**: Combines vector search, BM25, graph search, and hierarchical search
- **Multiple LLM Support**: Integration with OpenAI, Gemini, Ollama, and HuggingFace models
- **Real-time Processing**: Background data updates and incremental indexing
- **RESTful API**: Complete API for data ingestion and querying

### Advanced RAG Features
- **Cross-Encoder Reranking**: Improves retrieval quality with neural reranking
- **Multi-step Reasoning**: Complex query decomposition and iterative refinement
- **Self-reflection**: Built-in answer quality assessment
- **Hierarchical Search**: Email thread and document structure awareness
- **Graph-based Retrieval**: Knowledge graph construction and traversal
- **Context Filtering**: Intelligent relevance and redundancy filtering

## ğŸ“ Project Structure

```
cppa-brain-backend/
â”œâ”€â”€ api/                          # REST API endpoints
â”‚   â”œâ”€â”€ vector_data_api.py       # Main API server
â”‚   â”œâ”€â”€ chat_history_manager.py  # Conversation management
â”‚   â””â”€â”€ POST_API_Guide.md        # API documentation
â”œâ”€â”€ config/                       # Configuration files
â”‚   â””â”€â”€ config.yaml              # System configuration
â”œâ”€â”€ data_processor/               # Document processing modules
â”‚   â”œâ”€â”€ multiformat_processor.py # Multi-format document handler
â”‚   â”œâ”€â”€ semantic_chunker.py     # Semantic text chunking
â”‚   â”œâ”€â”€ summarize_processor.py   # Document summarization
â”‚   â””â”€â”€ mail_json_processor.py   # Email archive processing
â”œâ”€â”€ rag/                         # RAG system components
â”‚   â”œâ”€â”€ improved_rag_system.py  # Main RAG orchestrator
â”‚   â”œâ”€â”€ document_graph.py        # Knowledge graph management
â”‚   â”œâ”€â”€ mail_hierarchical_rag.py # Email thread processing
â”‚   â”œâ”€â”€ reranker.py             # Cross-encoder reranking
â”‚   â”œâ”€â”€ evaluation_system.py    # RAG evaluation metrics
â”‚   â””â”€â”€ langchain/              # LangChain integration
â”œâ”€â”€ text_generation/             # LLM integration modules
â”‚   â”œâ”€â”€ llm_manager.py          # LLM orchestration
â”‚   â”œâ”€â”€ openai_chatbot.py       # OpenAI integration
â”‚   â”œâ”€â”€ gemini_chatbot.py       # Google Gemini integration
â”‚   â”œâ”€â”€ ollama_chatbot.py       # Ollama local models
â”‚   â””â”€â”€ huggingface_chatbot.py # HuggingFace models
â”œâ”€â”€ utils/                       # Utility modules
â”‚   â””â”€â”€ config.py               # Configuration management
â”œâ”€â”€ templates/                   # Web interface templates
â””â”€â”€ main_pipeline.py            # Main pipeline orchestrator
```

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.8+
- Git
- Virtual environment (recommended)

### Setup
```bash
# Clone the repository
git clone <repository-url>
cd cppa-brain-backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure the system
cp config/config.yaml.example config/config.yaml
# Edit config/config.yaml with your settings
```

### Dependencies
Key dependencies include:
- `fastapi` - Web framework
- `sentence-transformers` - Embedding models
- `faiss` / `chromadb` - Vector databases
- `langchain` - RAG framework
- `transformers` - HuggingFace models
- `loguru` - Logging
- `pydantic` - Data validation

## âš™ï¸ Configuration

The system is configured through `config/config.yaml`. Key configuration sections:

### Embedding Models
```yaml
rag:
  embedding:
    embedding_types_list: ["gemma", "minilm", "nomic", "jina", "baai"]
    default_embedding_type: "minilm"
```

### Vector Databases
```yaml
rag:
  database:
    db_types_list: ["faiss", "chroma"]
    default_db_type: "faiss"
```

### LLM Integration
```yaml
rag:
  llm:
    llm_types_list: ["gemini", "ollama", "openai", "huggingface"]
    default_llm_type: "ollama"
```

## ğŸš€ Usage

### Starting the Pipeline
```bash
# Run the main pipeline
python main_pipeline.py

# Run with specific configuration
python main_pipeline.py --config config/config.yaml --language en
```

### API Server
```bash
# Start the API server
python -m api.vector_data_api

# The API will be available at http://localhost:8000
```

### Web Interface
```bash
# Access the web interface
# Open templates/index.html in your browser
```

## ğŸ“¡ API Endpoints

### Data Ingestion
- `POST /api/scrape` - Scrape and process new documents
- `POST /api/maillist/thread/new` - Add email thread data
- `POST /api/messages/thread/new` - Add email messages

### Query Interface
- `POST /api/query` - Query the RAG system
- `GET /api/status` - System status
- `GET /api/stats` - System statistics

### Example Query
```bash
curl -X POST "http://localhost:8000/api/query" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "How do I use Boost.Asio for asynchronous networking?",
    "max_results": 5,
    "use_reranker": true
  }'
```

## ğŸ”§ Advanced Features

### Multi-step Reasoning
The system supports complex query decomposition:
```python
# Enable multi-step reasoning
query_config = {
    "use_multi_step": True,
    "max_steps": 5,
    "confidence_threshold": 0.8
}
```

### Hierarchical Search
Email threads are processed with hierarchical structure:
- Thread-level context
- Message-level details
- Sender and relationship tracking

### Graph-based Retrieval
Knowledge graphs capture document relationships:
- Document similarity
- Concept relationships
- Cross-reference links

## ğŸ“Š Evaluation

The system includes comprehensive evaluation metrics:
- **Groundedness**: Answer accuracy to source documents
- **Faithfulness**: Consistency with retrieved context
- **Relevance**: Query-answer alignment
- **Completeness**: Answer thoroughness

## ğŸ”„ Data Processing Pipeline

1. **Scraping**: Extract documents from Boost.org
2. **Processing**: Multi-format document parsing
3. **Chunking**: Semantic text segmentation
4. **Embedding**: Vector representation generation
5. **Indexing**: Vector and search index creation
6. **Graph Construction**: Knowledge graph building

## ğŸ¯ Use Cases

- **Documentation Q&A**: Answer questions about Boost libraries
- **Code Examples**: Provide compilable code snippets
- **Mailing List Search**: Find relevant discussions and solutions
- **Learning Assistant**: Guide users through Boost concepts
- **Research Support**: Academic and professional research

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For questions and support:
- Check the API documentation in `api/POST_API_Guide.md`
- Review configuration options in `config/config.yaml`
- Examine the main pipeline in `main_pipeline.py`

## ğŸ”® Future Enhancements

- Real-time collaboration features
- Advanced graph analytics
- Multi-language support expansion
- Performance optimization
- Enhanced evaluation metrics
